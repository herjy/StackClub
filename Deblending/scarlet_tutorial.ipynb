{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deblending with *Scarlet*\n",
    "<br>Owner(s): **Fred Moolekamp** ([@fred3m](https://github.com/LSSTScienceCollaborations/StackClub/issues/new?body=@fred3m))\n",
    "<br>Last Verified to Run: **2020-07-10**\n",
    "<br>Verified Stack Release: **v20.0.0**\n",
    "\n",
    "The purpose of this tutorial is to familiarize you with the basics of using *scarlet* to model blended scenes, and how tweaking various objects and parameters affects the resulting model. A tutorial that is more specific to using scarlet in the context of the LSST DM Science Pipelines is also available.\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "After working through this tutorial you should be able to: \n",
    "1. Configure and run _scarlet_ on a test list of objects;\n",
    "2. Understand its various model assumptions and applied constraints.\n",
    "3. Use specific configurations to fit objects of different nature (stars, galaxies, LSBG)\n",
    "4. Bonus: we would like to give users a sense of how they can use their own assumptions to build models in scarlet\n",
    "\n",
    "Before attempting this tutorial it will be useful to read the [introduction](https://fred3m.github.io/scarlet/user_docs.html) to the *scarlet* User Guide, and many of the exercises below may require referencing the *scarlet* [docs](https://fred3m.github.io/scarlet/).\n",
    "\n",
    "### Logistics\n",
    "This notebook is intended to be runnable on `cori.nersc.gov` from a local git clone of https://github.com/LSSTDESC/StackClub.\n",
    "\n",
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version of the Stack are we using?\n",
    "! echo $HOSTNAME\n",
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# don't interpolate the pixels\n",
    "matplotlib.rc('image', interpolation='none')\n",
    "\n",
    "import numpy as np\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping\n",
    "\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping, LinearMapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also load the butler and various lsst packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lsst.daf.persistence import Butler\n",
    "from lsst.geom import Box2I, Box2D, Point2I, Point2D, Extent2I, Extent2D\n",
    "from lsst.afw.image import Exposure, Image, PARENT, MultibandExposure, MultibandImage\n",
    "from lsst.afw.detection import MultibandFootprint\n",
    "from lsst.afw.image import MultibandExposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Display the data\n",
    "\n",
    "More information are provided in the `lsst_stack_deblender.ipynb` tutorial. \n",
    "\n",
    "The **butler** is used to recover data from DESC DC2 DR6 by specifying the tract, patch and filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import desc_dc2_dm_data\n",
    "butler = desc_dc2_dm_data.get_butler(\"2.2i_dr6_wfd\")\n",
    "dataId = {\"tract\": 3830, \"patch\": \"4,4\"}\n",
    "filters = \"ugrizy\"\n",
    "coadds = [butler.get(\"deepCoadd_calexp\", dataId, filter=f) for f in filters]\n",
    "coadds = MultibandExposure.fromExposures(filters, coadds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then display the patch of data using display functions built-in in scarlet. The `norm` is used to create a colour scaling that avoids whitening the center of bright-ish objects also known as _Luptonisation_. \n",
    "\n",
    "The `image_to_rgb` function maps multi-band arrays into 3-channel RGB images. The mapping is done automatically by default, assuming an ordering of bands from bluer to redder, but it can be customised using the `channel_map` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = scarlet.display.AsinhMapping(minimum=0, stretch=1, Q=10)\n",
    "rgb_patch = scarlet.display.img_to_rgb(coadds.image.array, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,30))\n",
    "plt.imshow(rgb_patch, origin = \"lower\")\n",
    "plt.xticks(fontsize = 30)\n",
    "plt.yticks(fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's formalise the previous display procedure into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_rgb(image, norm = None, figsize = None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: `numpy.ndarrray`\n",
    "        Multiband image to display\n",
    "    norm: `scarlet.display.AsinhMapping`\n",
    "    \"\"\"\n",
    "    if norm == None:\n",
    "        norm = scarlet.display.AsinhMapping(minimum=0, stretch=1, Q=10)\n",
    "    rgb_patch = scarlet.display.img_to_rgb(image, norm=norm)\n",
    "    if figsize == None:\n",
    "        figsize = (30,30)\n",
    "        \n",
    "    plt.figure(figsize = figsize)\n",
    "    plt.imshow(rgb_patch, origin = \"lower\")\n",
    "    plt.xticks(fontsize = 30)\n",
    "    plt.yticks(fontsize = 30)\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display a subset\n",
    "\n",
    "Here we extract a patch from the previous image to run scarlet on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 180\n",
    "sampleBBox = Box2I(Point2I(16880, 19320), Extent2I(n, n))\n",
    "\n",
    "subset = coadds[:, sampleBBox]\n",
    "# Due to a bug in the code the PSF isn't copied properly.\n",
    "# The code below copies the PSF into the `MultibandExposure`,\n",
    "# but will be unecessary in the future\n",
    "for f in subset.filters:\n",
    "    subset[f].setPsf(coadds[f].getPsf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_rgb(subset.image.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the psfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfs = subset.computePsfImage(Point2I(16880, 19320)).array\n",
    "psf_norm = scarlet.display.AsinhMapping(minimum=0, stretch=0.001, Q=10)\n",
    "imshow_rgb(psfs, norm = psf_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model and observation frames\n",
    "\n",
    "A `Frame` in scarlet is the metadata that describes where the model lives. It includes the frames shape, wcs (optional), and the PSF (technically optional but strongly recommended). \n",
    "\n",
    "The `Observation` defines where the data lives, but also how to go from the model frame to the data. It contains the data themselves as an array but also meta-information such as channels tags, psf (technically optional but strongly recommended), wcs(optional) and weights (optional). The `Observation` needs to be matched to the `Frame` through the `match()` method. \n",
    "In scarlet it is possible to deblend scenes that have observations with different instruments that have different resolutions and/or observations that have not been coadded by building a list of `Observation`s. The `Frame` can be automatically built from the list of `Observation`s, however that is outside the scope of this tutorial and the interested reader should be referred to https://fred3m.github.io/scarlet/tutorials/multiresolution.html.\n",
    "\n",
    "So we will create an initial model `Frame` that uses a narrow gaussian PSF and an `Observation` that consists of multiple bands of an HSC coadded image.\n",
    "\n",
    "See https://fred3m.github.io/scarlet/user_docs.html#Frame-and-Observation for more on `Frame`s and `Observation`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??scarlet.psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PSF image of a narrow gaussian to use as our image PSF\n",
    "\n",
    "channels = [f for f in filters]\n",
    "from functools import partial\n",
    "model_psf = partial(scarlet.psf.gaussian, sigma=0.9)\n",
    "model_psf /= model_psf.sum()\n",
    "# Make sure that the observation PSF is normalized (otherwise the scaling in PSF matching might be off)\n",
    "psfs = psfs / psfs.sum(axis=(1, 2))[:, None, None]\n",
    "\n",
    "# Create the initial frame (metadata for the model).\n",
    "# Note that we initialized a PSF with shape (Ny, Nx) but a frame\n",
    "# expects a PSf with shape (bands, Ny, Nx), so we have to\n",
    "# broadcast the model_psf into an extra dimension\n",
    "frame = scarlet.Frame(images.shape, psfs=model_psf, channels=filters)\n",
    "\n",
    "# Create our observation\n",
    "observation = scarlet.Observation(images, psfs=psfs, channels=filters, weights=weights).match(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Sources\n",
    "\n",
    "Astrophysical objects are modeled in scarlet as a collection of components, where each component has a single SED that is constant over it's morphology (band independent intensity). So a single source might have multiple components, like a bulge and disk, or a single component.\n",
    "\n",
    "The different classes that inherit from `Source` mainly differ in how they are initialized, and otherwise behave similarly during the optimization routine. This section illustrates the differences between different source initialization classes.\n",
    "\n",
    "### <span style=\"color:red\"> *WARNING* </span>\n",
    "Scarlet accepts source positions using the numpy/C++ convention of (y,x), which is different than the astropy and LSST stack convention of (x,y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we demonstrate the usage of `ExtendedSource`, which initializes each object as a single component with maximum flux at the peak that falls off monotonically and has 180 degree symmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [scarlet.ExtendedSource(frame, (peak[1], peak[0]), observation) for peak in peaks]\n",
    "\n",
    "# Display the initial guess for each source\n",
    "scarlet.display.show_sources(sources,\n",
    "                             norm=norm,\n",
    "                             observation=observation,\n",
    "                             show_rendered=True,\n",
    "                             show_observed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "* Experiment with the above code by using ; and using `MultiComponentSource`, which models a source as two components (a bulge and a disk) that are each symmetric and montonically decreasing from the peak.\n",
    "\n",
    "# Deblending a scene\n",
    "\n",
    "The `Blend` class contains the list of sources, the observation(s), and any other configuration parameters necessary to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can fit a model, given a maximum number of iterations and the relative error required for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data until the relative error is <= 1e-3,\n",
    "# for a maximum of 200 iterations\n",
    "blend = scarlet.Blend(sources, observation)\n",
    "%time blend.fit(200, e_rel = 1e-3)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two options for displaying the scene, using `scarlet.display.show_scene` function. This shows the model along with the observation information and the residuals defined as: `observation.images - model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources, norm=norm,linear=True, \n",
    "                           observation=observation, show_observed=True, \n",
    "                           label_sources=True, \n",
    "                           show_rendered=True, \n",
    "                           show_residual=True\n",
    "                          )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do it by hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and calculate the residual\n",
    "model = blend.get_model()\n",
    "model_ = observation.render(model)  # adapt model to observations. \n",
    "residual = images-model_\n",
    "\n",
    "# Create RGB images\n",
    "model_rgb = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "residual_rgb = scarlet.display.img_to_rgb(residual)\n",
    "\n",
    "# Show the data, model, and residual\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title(\"Data\")\n",
    "ax[1].imshow(model_rgb)\n",
    "ax[1].set_title(\"Model\")\n",
    "ax[2].imshow(residual_rgb)\n",
    "ax[2].set_title(\"Residual\")\n",
    "\n",
    "for k,component in enumerate(blend):\n",
    "    y,x = component.center\n",
    "    ax[0].text(x, y, k, color=\"w\")\n",
    "    ax[1].text(x, y, k, color=\"w\")\n",
    "    ax[2].text(x, y, k, color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* Experiment by running the above code using different source models (for example `MultiComponentSource` or `PointSource`) to see how initializtion affects the belnding results.\n",
    "\n",
    "* Change the value of `e_rel` in the above fit and try to understand how it affects the results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-dia",
   "language": "python",
   "name": "desc-dia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
