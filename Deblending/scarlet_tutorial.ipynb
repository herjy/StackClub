{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deblending with *Scarlet*\n",
    "<br>Owner(s): **Fred Moolekamp** ([@fred3m](https://github.com/LSSTScienceCollaborations/StackClub/issues/new?body=@fred3m))\n",
    "<br>Last Verified to Run: **2020-07-10**\n",
    "<br>Verified Stack Release: **v20.0.0**\n",
    "\n",
    "The purpose of this tutorial is to familiarize you with the basics of using *scarlet* to model blended scenes, and how tweaking various objects and parameters affects the resulting model. A tutorial that is more specific to using scarlet in the context of the LSST DM Science Pipelines is also available.\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "After working through this tutorial you should be able to: \n",
    "1. Configure and run _scarlet_ on a test list of objects;\n",
    "2. Understand its various model assumptions and applied constraints.\n",
    "3. Use specific configurations to fit objects of different nature (stars, galaxies, LSBG)\n",
    "4. Bonus: we would like to give users a sense of how they can use their own assumptions to build models in scarlet\n",
    "\n",
    "Before attempting this tutorial it will be useful to read the [introduction](https://fred3m.github.io/scarlet/user_docs.html) to the *scarlet* User Guide, and many of the exercises below may require referencing the *scarlet* [docs](https://fred3m.github.io/scarlet/).\n",
    "\n",
    "### Logistics\n",
    "This notebook is intended to be runnable on `cori.nersc.gov` from a local git clone of https://github.com/LSSTDESC/StackClub.\n",
    "\n",
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version of the Stack are we using?\n",
    "! echo $HOSTNAME\n",
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# don't interpolate the pixels\n",
    "matplotlib.rc('image', interpolation='none')\n",
    "\n",
    "import numpy as np\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping\n",
    "\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "from scarlet import Starlet\n",
    "import pickle\n",
    "\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping, LinearMapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also load the butler and various lsst packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lsst\n",
    "from lsst.daf.persistence import Butler\n",
    "from lsst.geom import Box2I, Box2D, Point2I, Point2D, Extent2I, Extent2D\n",
    "from lsst.afw.image import Exposure, Image, PARENT, MultibandExposure, MultibandImage\n",
    "from lsst.afw.detection import MultibandFootprint\n",
    "from lsst.afw.image import MultibandExposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Display the data\n",
    "\n",
    "More information are provided in the `lsst_stack_deblender.ipynb` tutorial. \n",
    "\n",
    "The **butler** is used to recover data from DESC DC2 DR6 by specifying the tract, patch and filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import desc_dc2_dm_data\n",
    "butler = desc_dc2_dm_data.get_butler(\"2.2i_dr6_wfd\")\n",
    "dataId = {\"tract\": 3830, \"patch\": \"4,4\"}\n",
    "filters = \"ugrizy\"\n",
    "coadds = [butler.get(\"deepCoadd_calexp\", dataId, filter=f) for f in filters]\n",
    "coadds = MultibandExposure.fromExposures(filters, coadds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then display the patch of data using display functions built-in in scarlet. The `norm` is used to create a colour scaling that avoids whitening the center of bright-ish objects also known as _Luptonisation_. \n",
    "\n",
    "The `image_to_rgb` function maps multi-band arrays into 3-channel RGB images. The mapping is done automatically by default, assuming an ordering of bands from bluer to redder, but it can be customised using the `channel_map` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = scarlet.display.AsinhMapping(minimum=0, stretch=1, Q=10)\n",
    "rgb_patch = scarlet.display.img_to_rgb(coadds.image.array, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,30))\n",
    "plt.imshow(rgb_patch, origin = \"lower\")\n",
    "plt.xticks(fontsize = 30)\n",
    "plt.yticks(fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's formalise the previous display procedure into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_rgb(image, norm = None, figsize = None, cat = None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: `numpy.ndarrray`\n",
    "        Multiband image to display\n",
    "    norm: `scarlet.display.AsinhMapping`\n",
    "    \"\"\"\n",
    "    if norm == None:\n",
    "        norm = scarlet.display.AsinhMapping(minimum=0, stretch=1, Q=10)\n",
    "    rgb_patch = scarlet.display.img_to_rgb(image, norm=norm)\n",
    "        \n",
    "    plt.figure(figsize = figsize)\n",
    "    plt.imshow(rgb_patch, origin = \"lower\")\n",
    "    plt.xticks(fontsize = 30)\n",
    "    plt.yticks(fontsize = 30)\n",
    "    #Display source positions\n",
    "    if cat != None:\n",
    "        plt.plot(cat['x'], cat['y'], 'wx', markersize = 15)\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display a subset\n",
    "\n",
    "Here we extract a patch from the previous image to run scarlet on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 180\n",
    "sampleBBox = Box2I(Point2I(16880, 19320), Extent2I(n, n))\n",
    "\n",
    "subset = coadds[:, sampleBBox]\n",
    "# Due to a bug in the code the PSF isn't copied properly.\n",
    "# The code below copies the PSF into the `MultibandExposure`,\n",
    "# but will be unecessary in the future\n",
    "for f in subset.filters:\n",
    "    subset[f].setPsf(coadds[f].getPsf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = subset.image.array\n",
    "imshow_rgb(images, figsize = (15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the psfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfs = subset.computePsfImage(Point2I(16880, 19320)).array\n",
    "psf_norm = scarlet.display.AsinhMapping(minimum=0, stretch=0.001, Q=10)\n",
    "imshow_rgb(psfs, norm = psf_norm, figsize = (15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scarlet background\n",
    "\n",
    "This short introduction to scarlet concepts is adapted from a notebook built by fred Moolekamp and Peter Melchior:\n",
    "    https://github.com/pmelchior/scarlet/blob/master/docs/1-concepts.ipynb.\n",
    "    \n",
    "Scarlet aims at modeling individual sourcess $S$ in image $Y$, convolved by the instrument psf $H$ and which contains additive noise $N$. The model for images is therefore: $$Y = H\\sum_i S_i + N$$\n",
    "\n",
    "In scarlet, images can be a cube of images observed at different wavelength. Scarlet is able to exploit the colour of each source to reconstruct invidual models by factorising a source into a spectra and a morphlogy such that, for a given source: $$S_i = A_iM_i$$ Here, $S_i$ is an array with the shape of the observations ($n_{channels}\\times n_{xpixels} \\times n_{ypixels}$), $A_i$ contains the $n_{channels}$ elements that make up the spectra of sources $S_i$ and $M_i$ contains the morphology of the source. The array that contains the morphology is classically a 2-D array with the same number of pixels as the observation.\n",
    "\n",
    "This decomposition is a choice made by the users of scarlet motivated the colour differences  betweeen sources in astronomical observations. However, it is possible to come up with other definition for sources that do not follow the previous predicaments. For instance, one could think of modelling each source in its entirety as an array $S_i$ that contains as many pixels as the observation, or to model each source as a linear decomposition over an arbitrary basis or as a non-linear analytic profile. \n",
    "\n",
    "Scarlet has the flexibility to enable these models, but it requires setting up the tools to go from an arbitrary model to the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the weights for inverse variance weighting\n",
    "\n",
    "Bands with higher noise variance are less informative to the fit, they are therefore down-waited in the optimisation. Here the variance is given for each pixel position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = subset.variance.array\n",
    "weights = 1 / (var ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model and observation frames\n",
    "\n",
    "A key concept is the interplay between `Frame` and `Observation`. While the data have their native resolution with a given pixel size and PSF, a model for galaxies can be built at arbitrary resolution. The `Frame` allows to define a sampling for the model and a psf to which the models are deconvolved \n",
    "\n",
    "A `Frame` in scarlet is the metadata that describes where the images of the model lives. It includes the frames shape, wcs (optional), and the PSF (technically optional but strongly recommended). \n",
    "\n",
    "The `Observation` defines where the data lives, but also how to go from the model frame to the data. It contains the data themselves as an array but also meta-information such as channels tags, psf (technically optional but strongly recommended), wcs(optional) and weights (optional). The `Observation` needs to be matched to the `Frame` through the `match()` method. \n",
    "In scarlet it is possible to deblend scenes that have observations with different instruments that have different resolutions and/or observations that have not been coadded by building a list of `Observation`s. The `Frame` can be automatically built from the list of `Observation`s, however that is outside the scope of this tutorial and the interested reader should be referred to https://fred3m.github.io/scarlet/tutorials/multiresolution.html.\n",
    "\n",
    "So we will create an initial model `Frame` that uses a narrow gaussian PSF and an `Observation` that consists of multiple bands of an HSC coadded image.\n",
    "\n",
    "See https://fred3m.github.io/scarlet/user_docs.html#Frame-and-Observation for more on `Frame`s and `Observation`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PSF image of a narrow gaussian to use as our image PSF\n",
    "channels = [f for f in filters]\n",
    "# Create a `scarlet.PSF` object\n",
    "model_psf = scarlet.GaussianPSF(sigma=0.9)\n",
    "\n",
    "# Create the initial frame (metadata for the model).\n",
    "frame = scarlet.Frame(images.shape, psfs=model_psf, channels=filters)\n",
    "\n",
    "# Create our observation\n",
    "observation = scarlet.Observation(images, psfs=scarlet.ImagePSF(psfs), channels=filters, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Observation` has to be matched to the `Frame`. The role of this operation is to create the diff-kernel that will deconvolve the data from their psf to the model psf (in the `Frame`). After this step we will be able to visualise the diff kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initially the diff kernel is initialised to None\n",
    "print(f'the diff kernel does not exist: {observation._diff_kernels}')\n",
    "#After matching, the diff kernel is instantiated\n",
    "observation.match(frame)\n",
    "imshow_rgb(observation._diff_kernels.image, norm = psf_norm, figsize = (15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "The next key concept to scarlet is that of `Source`s. `Source` objects describe how the model is parametrized and what constraints are used in the optimisation. A source is related to a position on the image grid and has a box size that determines the span of an object's light profile. \n",
    "\n",
    "## Detection\n",
    "\n",
    "One `Source` object corresponds to the light profile of an astronomical object. Scarlet therefore requires that objects be detected so that a source can be initialised. Scarlet requires a position in order to declare and initiate each source. Scarlet does not have a detection algorithm of its own and it is outside the scope of this tool, but we will provide here a custom detection. \n",
    "\n",
    "extension tools for scarlet such as this detection function can be found in the [scarlet  extensions](https://github.com/fred3m/scarlet_extensions) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCatalog(cube, lvl=3, wave=True):\n",
    "    ''' Creates a detection catalog by combining low and high resolution data\n",
    "    This function is used for detection before running scarlet.\n",
    "    It is particularly useful for stellar crowded fields and for detecting high frequency features.\n",
    "    Parameters\n",
    "    ----------\n",
    "    datas: array\n",
    "        array of Data objects\n",
    "    lvl: int\n",
    "        detection lvl\n",
    "    wave: Bool\n",
    "        set to True to use wavelet decomposition of images before combination\n",
    "    Returns\n",
    "    -------\n",
    "    catalog: sextractor catalog\n",
    "        catalog of detected sources\n",
    "    bg_rms: array\n",
    "        background level for each data set\n",
    "    '''\n",
    "    #Coadd all bands\n",
    "    detect_image = np.sum(cube, axis=0)\n",
    "\n",
    "    if np.size(detect_image.shape) == 3:\n",
    "        if wave:\n",
    "            # Wavelet detection in the first three levels\n",
    "            #Consider this a high pass filter\n",
    "            wave_detect = Starlet(detect_image.mean(axis=0), lvl=4).coefficients\n",
    "            wave_detect[:, -1, :, :] = 0\n",
    "            detect = Starlet(coefficients=wave_detect).image\n",
    "        else:\n",
    "            # Direct detection\n",
    "            detect = detect_image.mean(axis=0)\n",
    "    else:\n",
    "        if wave:\n",
    "            wave_detect = Starlet(detect_image).coefficients\n",
    "            detect = wave_detect[0][0]\n",
    "        else:\n",
    "            detect = detect_image\n",
    "\n",
    "    bkg = sep.Background(detect)\n",
    "    catalog = sep.extract(detect, lvl, err=bkg.globalrms)\n",
    "\n",
    "    if len(datas) ==1:\n",
    "        bg_rms = mad_wavelet(datas[0].images)\n",
    "    else:\n",
    "        bg_rms = []\n",
    "        for data in datas:\n",
    "            bg_rms.append(mad_wavelet(data.images))\n",
    "\n",
    "    return catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would normally run the detection algorithm on the DC2 images and display the result of the detection. However, this custom function requires sep which is not available on `desc-stack-weekly-latest`. Instead I ran the detection on my machine and show the result here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat = makeCatalog(images)\n",
    "cat = pickle.load(open('cat.pkl', 'rb'))\n",
    "imshow_rgb(images, figsize = (20,20), cat = cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Sources\n",
    "\n",
    "Astrophysical objects are generally modeled in scarlet as a collection of factorized components, where each component has a single SED that is constant over it's morphology (band independent intensity). So a single source might have multiple components, like a bulge and disk, or a single component.\n",
    "\n",
    "The different classes that inherit from `FactorizedComponent` differ in how they are initialized and parametrized. This section illustrates the differences between different source initialization classes.\n",
    "\n",
    "### <span style=\"color:red\"> *WARNING* </span>\n",
    "Scarlet accepts source positions using the numpy/C++ convention of (y,x), which is different than the astropy and LSST stack convention of (x,y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we demonstrate the usage of `ExtendedSource`, which initializes each object as a single component with maximum flux at the peak that falls off monotonically and has 180 degree symmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [scarlet.ExtendedSource(frame, (c['y'], c['x']), observation) for c in cat]\n",
    "\n",
    "scarlet.display.show_scene(sources, \n",
    "                           norm = norm, \n",
    "                           observation=observation, \n",
    "                           show_observed=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the initial guess for each source\n",
    "scarlet.display.show_sources(sources,\n",
    "                             norm=norm,\n",
    "                             observation=observation,\n",
    "                             show_rendered=True,\n",
    "                             show_observed=True,\n",
    "                             add_boxes = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "* Experiment with various `Source` classes: `PointSource`, `MultiExtendedSource` (`Extended` source with arg K = 1), `StarletSource`.\n",
    "* Pick a different source depending on the visual appearance of the objects.\n",
    "* Later: run scarlet with different initializations.\n",
    "* For the boldest and bravest: come up with your own sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "for i in range(len(cat)):\n",
    "    if i in \"\"\"list of detected images\"\"\":\n",
    "        source = scarlet.\"\"\"Your favourite kind of source\"\"\"\n",
    "    else:\n",
    "        source = scarlet.ExtendedSource(frame, (cat[i]['y'], cat[i]['x']), observation) \n",
    "    sources.append(source)    \n",
    "    \n",
    "scarlet.display.show_scene(sources, \n",
    "                           norm = norm, \n",
    "                           observation=observation, \n",
    "                           show_rendered=True, \n",
    "                           show_observed=True, \n",
    "                           show_residual=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deblending a scene\n",
    "\n",
    "the `Blend` class contains the list of sources, the observations(s) and any other configuration parameters necessary to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can fit a model, given a maximum number of iterations and the relative error required for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data until the relative error is <= 1e-3,\n",
    "# for a maximum of 200 iterations\n",
    "%time blend.fit(200, e_rel = 1e-3)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two options for displaying the scene, using `scarlet.display.show_scene` function. This shows the model along with the observation information and the residuals defined as: `observation.images - model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources, norm=norm,linear=True, \n",
    "                           observation=observation, \n",
    "                           show_observed=True, \n",
    "                           show_rendered=True, \n",
    "                           show_residual=True\n",
    "                          )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scarlet can perform basiic measurements on sources. Given that sources are isolated and nosiie less, one can for nstace compute the flux of each source in each band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = []\n",
    "for s in sources:\n",
    "    fluxes.append(scarlet.measure.flux(s))\n",
    "    \n",
    "plt.plot(np.array(fluxes).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the initial guess for each source\n",
    "scarlet.display.show_sources(sources,\n",
    "                             norm=norm,\n",
    "                             observation=observation,\n",
    "                             show_rendered=True,\n",
    "                             show_observed=True,\n",
    "                             add_boxes = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To go further\n",
    "\n",
    "Sources as `FactorizedComponents` are made of a `TabulatedSpectrum` that describes the contribution of a source to each band, and a `Morphology` that discribes the 2D profile of the source. Depending on the source one may want to impose different constraints on what the shape of the galaxy may look like. This is done by building a set of constraints associated with the parameters of the morphology.\n",
    "\n",
    "Let us declare a custom-ish `Source` class, initialize sources with it and see how it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarlet import TabulatedSpectrum, FactorizedComponent, init_extended_source, ImageMorphology\n",
    "\n",
    "class NewSourceMorphology(ImageMorphology):\n",
    "    def __init__(\n",
    "        self,\n",
    "        frame,\n",
    "        center,\n",
    "        image,\n",
    "        bbox=None,\n",
    "        shifting=False,\n",
    "    ):\n",
    "        \"\"\"Non-parametric image morphology designed for galaxies as extended sources.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame: `~scarlet.Frame`\n",
    "            The frame of the full model\n",
    "        center: tuple\n",
    "            Center of the source\n",
    "        image: `numpy.ndarray`\n",
    "            Image of the source.\n",
    "        bbox: `~scarlet.Box`\n",
    "            2D bounding box for focation of the image in `frame`\n",
    "        monotonic: ['flat', 'angle', 'nearest'] or None\n",
    "            Which version of monotonic decrease in flux from the center to enforce\n",
    "        symmetric: `bool`\n",
    "            Whether or not to enforce symmetry.\n",
    "        min_grad: float in [0,1)\n",
    "            Minimal radial decline for monotonicity (in units of reference pixel value)\n",
    "        shifting: `bool`\n",
    "            Whether or not a subpixel shift is added as optimization parameter\n",
    "        \"\"\"\n",
    "\n",
    "        constraints = []\n",
    "        # backwards compatibility: monotonic was boolean\n",
    "        if monotonic is True:\n",
    "            monotonic = \"angle\"\n",
    "        elif monotonic is False:\n",
    "            monotonic = None\n",
    "        if monotonic is not None:\n",
    "            # most astronomical sources are monotonically decreasing\n",
    "            # from their center\n",
    "            constraints.append(\n",
    "                MonotonicityConstraint(neighbor_weight=monotonic, min_gradient=min_grad)\n",
    "            )\n",
    "\n",
    "\n",
    "        constraints += [\n",
    "            # most astronomical sources are monotonically decreasing\n",
    "            MonotonicityConstraint(),\n",
    "            # have 2-fold rotation symmetry around their center ...\n",
    "            SymmetryConstraint(),\n",
    "            # ... and are positive emitters\n",
    "            PositivityConstraint(),\n",
    "            # prevent a weak source from disappearing entirely\n",
    "            CenterOnConstraint(),\n",
    "            # break degeneracies between sed and morphology\n",
    "            NormalizationConstraint(\"max\"),\n",
    "        ]\n",
    "        morph_constraint = ConstraintChain(*constraints)\n",
    "        image = Parameter(image, name=\"image\", step=1e-2, constraint=morph_constraint)\n",
    "\n",
    "        self.pixel_center = np.round(center).astype(\"int\")\n",
    "        if shifting:\n",
    "            shift = Parameter(center - self.pixel_center, name=\"shift\", step=1e-1)\n",
    "        else:\n",
    "            shift = None\n",
    "        self.shift = shift\n",
    "\n",
    "        super().__init__(frame, image, bbox=bbox, shift=shift)\n",
    "\n",
    "    @property\n",
    "    def center(self):\n",
    "        if self.shift is not None:\n",
    "            return self.pixel_center + self.shift\n",
    "        else:\n",
    "            return self.pixel_center\n",
    "\n",
    "        \n",
    "class NewExtendedSource(FactorizedComponent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_frame,\n",
    "        sky_coord,\n",
    "        observations,\n",
    "        coadd=None,\n",
    "        coadd_rms=None,\n",
    "        thresh=1.0,\n",
    "        compact=False,\n",
    "        shifting=False,\n",
    "    ):\n",
    "        \"\"\"Extended source model\n",
    "\n",
    "        The model is initialized from `observations` with a symmetric and\n",
    "        monotonic profile and a spectrum from its peak pixel.\n",
    "\n",
    "        During optimization it enforces positivitiy for spectrum and morphology,\n",
    "        as well as monotonicity of the morphology.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_frame: `~scarlet.Frame`\n",
    "            The frame of the full model\n",
    "        sky_coord: tuple\n",
    "            Center of the source\n",
    "        observations: instance or list of `~scarlet.observation.Observation`\n",
    "            Observation(s) to initialize this source.\n",
    "        coadd: `numpy.ndarray`\n",
    "            The coaddition of all images across observations.\n",
    "        coadd_rms: float\n",
    "            Noise level of the coadd\n",
    "        thresh: `float`\n",
    "            Multiple of the backround RMS used as a\n",
    "            flux cutoff for morphology initialization.\n",
    "        compact: `bool`\n",
    "            Initialize with the shape of a point source\n",
    "        shifting: `bool`\n",
    "            Whether or not a subpixel shift is added as optimization parameter\n",
    "        \"\"\"\n",
    "        # initialize from observation\n",
    "        spectrum, morph, bbox = init_extended_source(\n",
    "                sky_coord,\n",
    "                model_frame,\n",
    "                observations,\n",
    "                coadd,\n",
    "                coadd_rms=coadd_rms,\n",
    "                thresh=thresh,\n",
    "                compact=compact,\n",
    "                symmetric=True,\n",
    "                monotonic=\"flat\",\n",
    "                min_grad=0,\n",
    "            )\n",
    "\n",
    "        spectrum = TabulatedSpectrum(model_frame, spectrum, bbox=bbox[0])\n",
    "\n",
    "        center = model_frame.get_pixel(sky_coord)\n",
    "        morphology = NewSourceMorphology(\n",
    "            model_frame,\n",
    "            center,\n",
    "            morph,\n",
    "            bbox=bbox[1:],\n",
    "            shifting=shifting,\n",
    "        )\n",
    "        self.center = morphology.center\n",
    "        super().__init__(model_frame, spectrum, morphology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Your turn now, deblend this: Using the detection catalog I provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching images\n",
    "cutout_size = 300\n",
    "cutout_extent = lsst.geom.ExtentI(cutout_size, cutout_size)\n",
    "skymap = butler.get('deepCoadd_skyMap')\n",
    "radec = lsst.geom.SpherePoint(56.811321, -31.123123, lsst.geom.degrees)\n",
    "center = skymap.findTract(radec).getWcs().skyToPixel(radec)\n",
    "bbox = lsst.geom.BoxI(lsst.geom.Point2I((center.x - cutout_size*0.5, center.y - cutout_size*0.5)), cutout_extent)\n",
    "\n",
    "cutouts = [butler.get(\"deepCoadd_sub\", bbox=bbox, tract=4639, patch='1,0', filter=band) for band in \"ugrizy\"]\n",
    "coadds = MultibandExposure.fromExposures(\"ugrizy\", cutouts)\n",
    "\n",
    "# PSF\n",
    "psfs = coadds.computePsfImage(Point2I(center.x - cutout_size*0.5, center.y - cutout_size*0.5)).array\n",
    "#Cube image\n",
    "cube = coadds.image.array\n",
    "#Weights\n",
    "var2 = coadds.variance.array\n",
    "weights2 = 1 / (var ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the catalog of detections along with the image of the patch. \n",
    "Note here that the catalog was generated by running sep directly on the images, without using wavelet filtering.\n",
    "Wavelet filtering actually causes the substructures to be detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open cat\n",
    "cat = pickle.load(open('cat2.pkl', 'rb'))\n",
    "#Display image\n",
    "imshow_rgb(cube, figsize = (20,20), cat = cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Setup the frame and observation and match them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PSF image of a narrow gaussian to use as our image PSF\n",
    "channels = \"...\"\n",
    "# Create a model psf using `scarlet.PSF` object\n",
    "model_psf = \"...\"\n",
    "\n",
    "# Create the initial frame (metadata for the model).\n",
    "frame = scarlet.frame(\"...\")\n",
    "\n",
    "# Create our observation\n",
    "observation = scarlet.Observation(\"...\").match(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Initialize the sources and display the intial model. \n",
    "\n",
    "Once your first try of running scarlet on the patch over, try changing the sources you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"You're on your own here, you'll have to declare the sources\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "scarlet.display.show_scene(sources, \n",
    "                           norm = norm, \n",
    "                           observation=observation, \n",
    "                           show_observed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Task 3\n",
    "\n",
    "Run scarlet and display the results. Suggestion, play with the e_rel parameter to see how it improves the fit. e_rel is the criteria of convergence. The smaller e_rel the longer the algorithm will run until converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)\n",
    "%time blend.fit(200, e_rel = 1e-3)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Display \n",
    "...\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack-weekly-latest",
   "language": "python",
   "name": "desc-stack-weekly-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
